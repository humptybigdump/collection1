{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward neural networks, Autoencoders and CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook will cover the topics:\n",
    "\n",
    "* Feed-forward neural network \n",
    "* Autoencoder\n",
    "* Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the Keras module from TensorFlow package. TensorFlow is an open-source library for machine learning and deep learning created by Google.\n",
    "\n",
    "At first we're importing the mnist dataset (large database of handwritten digits) and preparing it for the neural network. That includes normalizing the images (giving each pixel the value between 0 and 1) and flattening it\n",
    "(turning (28, 28) matrix into (1, 784) array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the data\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images\n",
    "train_images = (train_images / 255) \n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Flatten the images\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Complete the code below to build a 3-layer model with the following conditions:\n",
    "* the activation function for both hidden layers is **sigmoid**\n",
    "* each hidden layer has **64 units**\n",
    "* the activation function for the output layer is **softmax**\n",
    "\n",
    "*Notes:* \n",
    "* input_shape parameter is only needed in the first hidden layer\n",
    "* number of output units should be equal to the number of classes that we want to classify (in our case - 10 digits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "input_num_units = 784\n",
    "hidden_units = 64 \n",
    "output_units = 10 \n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(hidden_units, activation='sigmoid', input_shape=(input_num_units,)),\n",
    "    Dense(hidden_units, activation='sigmoid'), \n",
    "    Dense(output_units, activation='softmax'), \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy', # using this loss function because we have more than 2 classes to classify\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Copy your model from the cell above and add 2 Dropout layers (50% Dropout rate for each Dropout layer) between the actual layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "input_num_units = 784\n",
    "hidden_units = 64 \n",
    "output_units = 10\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Build the model\n",
    "model_drop = Sequential([\n",
    "    Dense(hidden_units, activation='sigmoid', input_shape=(input_num_units,)),\n",
    "    Dropout(dropout_rate), \n",
    "    Dense(hidden_units, activation='sigmoid'), \n",
    "    Dropout(dropout_rate),\n",
    "    Dense(output_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_drop.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without dropout layers.\\n\")\n",
    "\n",
    "# Train the model without dropout layers\n",
    "history = model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=100,\n",
    ")\n",
    "\n",
    "print(\"\\nModel with 2 dropout layers.\\n\")\n",
    "\n",
    "# Train the model with dropout layers\n",
    "history_drop = model_drop.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in our case the model with dropout layers has slower convergence than a model without them.\n",
    "We're going to plot the results for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function for both models\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(20,6))\n",
    "ax1.plot(np.sqrt(history.history['loss']), 'r', label='without_drop')\n",
    "ax1.plot(np.sqrt(history_drop.history['loss']), 'b', label='with_drop')\n",
    "ax1.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax1.set_ylabel(r'Loss', fontsize=20)\n",
    "ax1.legend()\n",
    "ax1.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy for both models\n",
    "ax2.plot(np.sqrt(history.history['accuracy']), 'r', label='without_drop')\n",
    "ax2.plot(np.sqrt(history_drop.history['accuracy']), 'b', label='with_drop')\n",
    "ax2.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax2.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax2.legend()\n",
    "ax2.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model without dropout layers\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate model with dropout layers\n",
    "model_drop.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the difference between the accuracy values you see in the plot above and the accuracy values you received just now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we're going to show you the structure of the simple autoencoder. It has only 1 layer for encoding and 1 layer for decoding.\n",
    "\n",
    "We're using the same mnist dataset for this task. The autoencoder is a form of unsupervised learning, that's why we don't need labels for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "encoding_dim = 32 # size of the encoded representation\n",
    "input_dim = 784 # size of the input\n",
    "\n",
    "input_img = Input(shape=(784,)) # input image\n",
    "\n",
    "# Maps input image to its encoded representation\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# Maps encoded representation to its reconstruction\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Maps input image to its reconstruction\n",
    "simple_autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're training our simple autoencoder. The next cell takes some time to be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder\n",
    "simple_autoencoder.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "simple_autoencoder.fit(train_images, train_images,\n",
    "                epochs=25,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're building a more complex autoencoder with mutiple layers for encoding and decoding.\n",
    "\n",
    "Structure of the single layer looks like :\n",
    "\n",
    "current_layer_output = Dense(num_dimensions, activation = \"...\")(previous_layer_output)\n",
    "\n",
    "**Task:** Build the autoencoder with 3 layers for encoding and 3 layers for decoding using 'relu' as activation function for all layers except the last decoding layer, for which we're using 'sigmoid'.\n",
    "\n",
    "*Note:* \n",
    "* num_dimension for the last encoded layer should be equal to the desired size of the encoded representation (we use 32 as in the last example)\n",
    "* num_dimension for the last decoded layer should be equal to the original image size (in our case - 784)\n",
    "* you can use the following dimension reduction in your encoding layers = (128, 64, 32)\n",
    "* you can use the following dimension restoring in your decoding layers = (64, 128, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "encoding_dim = 32 # size of the encoded representation\n",
    "input_dim = 784 # size of the input\n",
    "\n",
    "input_img = Input(shape=(784,)) # input image\n",
    "\n",
    "# Maps input image to its encoded representation in multiple steps\n",
    "encoded_1 = Dense(128, activation='relu')(input_img)\n",
    "encoded_2 = Dense(64, activation='relu')(encoded_1) \n",
    "encoded_3 = Dense(32, activation='relu')(encoded_2) \n",
    "\n",
    "# Maps encoded representation to its reconstruction in multiple steps\n",
    "decoded_1 = Dense(64, activation='relu')(encoded_3) \n",
    "decoded_2 = Dense(128, activation='relu')(decoded_1)\n",
    "decoded_3 = Dense(784, activation='sigmoid')(decoded_2) \n",
    "\n",
    "# Maps an input image to its reconstruction\n",
    "deep_autoencoder = Model(input_img, decoded_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're training our deep autoencoder. This cell also takes time to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "deep_autoencoder.fit(train_images, train_images,\n",
    "                epochs=25,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to compare the original images with the result images of our two autoencoders. \n",
    "The result images of simple and deep autoencoders look very similar, because we didn't do extra processing of the images but only added some layers in the deep_autoencoder.\n",
    "\n",
    "We can still see, that the value of the loss function has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_encoded_imgs = simple_autoencoder.predict(test_images) # images encoded with simple_autoencoder\n",
    "deep_encoded_imgs = deep_autoencoder.predict(test_images) # images encoded with deep_autoencoder\n",
    "\n",
    "n = 10 # number of images we want to check\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(test_images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(3, n, i + n)\n",
    "    plt.imshow(simple_encoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(3, n, i + n + n)\n",
    "    plt.imshow(deep_encoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're reusing mnist dataset. But this time we need to change the shape of the images after normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255)\n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3) # now the images have the shape (28,28,1)\n",
    "test_images = np.expand_dims(test_images, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Build a CNN using Sequential class from the Keras module\n",
    "\n",
    "Your CNN should have the following layers:\n",
    "* 2D convolution layer with 16 3x3 filters\n",
    "* 2D max pooling layer with 2x2 pooling window\n",
    "* 2D convolution layer with 16 3x3 filters\n",
    "* fully connected layer with 'relu' activation function and 64 units (Dense layer)\n",
    "* 2D max pooling layer with 2x2 pooling window\n",
    "* Dropout layer with 50% Dropout rate\n",
    "* fully connected layer with 'softmax' activation function and 10 units - output layer\n",
    "\n",
    "*Note:* Don't forget to flatten your input before the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "# Define variables\n",
    "num_filters = 16\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "hidden_units = 64 \n",
    "output_units = 10\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Conv2D(num_filters, filter_size),\n",
    "    Dense(hidden_units, activation='relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(dropout_rate),\n",
    "    Flatten(),\n",
    "    Dense(output_units, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Compile your model using 'adam' optimizer, 'categorical_crossentropy' as loss function and only 'accuracy' in metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "history_cnn=model.fit(\n",
    "    train_images,\n",
    "    to_categorical(train_labels),\n",
    "    batch_size = 128,\n",
    "    epochs=5,\n",
    "    validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our CNN model is around 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to plot the loss function and accuracy of the training and validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(20,6))\n",
    "ax1.plot(np.sqrt(history_cnn.history['val_loss']), 'b', label='val')\n",
    "ax1.plot(np.sqrt(history_cnn.history['loss']), 'g' ,label='train')\n",
    "ax1.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax1.set_ylabel(r'Loss', fontsize=20)\n",
    "ax1.legend()\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "# Plot the accuracy\n",
    "ax2.plot(np.sqrt(history_cnn.history['val_accuracy']), 'b', label='val')\n",
    "ax2.plot(np.sqrt(history_cnn.history['accuracy']), 'g' ,label='train')\n",
    "ax2.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax2.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax2.legend()\n",
    "ax2.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to compare our feed-forward neural network (without dropout layers) and convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(20,6))\n",
    "ax1.plot(np.sqrt(history.history['loss']), 'r', label='without_drop')\n",
    "ax1.plot(np.sqrt(history_cnn.history['loss']), 'g' ,label='cnn')\n",
    "ax1.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax1.set_ylabel(r'Loss', fontsize=20)\n",
    "ax1.legend()\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "# Plot the accuracy\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax2.plot(np.sqrt(history.history['accuracy']), 'r', label='without_drop')\n",
    "ax2.plot(np.sqrt(history_cnn.history['accuracy']), 'g' ,label='cnn')\n",
    "ax2.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax2.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax2.legend()\n",
    "ax2.tick_params(labelsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see CNN performs better but needs more time for training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
